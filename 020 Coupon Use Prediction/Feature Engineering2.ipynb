{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Feature Engineering2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNm7uZULP94oFvi+lCIW4i/"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"1rCJHzDwx4lq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595936535775,"user_tz":-480,"elapsed":1082,"user":{"displayName":"Jiatao LI","photoUrl":"","userId":"09800313012843676250"}}},"source":["import numpy as np\n","import pandas as pd\n","\n","from datetime import date"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"_W3o2CtkOq-R","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"executionInfo":{"status":"ok","timestamp":1595936559569,"user_tz":-480,"elapsed":24864,"user":{"displayName":"Jiatao LI","photoUrl":"","userId":"09800313012843676250"}},"outputId":"c4d5e171-8b5d-4b58-aa66-e60f4192aa59"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9pVttohDOrK3","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595943436521,"user_tz":-480,"elapsed":10404,"user":{"displayName":"Jiatao LI","photoUrl":"","userId":"09800313012843676250"}}},"source":["train_offline_data_type = {'User_id': np.int64, 'Merchant_id': np.int64, 'Coupon_id': object,\n","              'Discount_rate': object, 'Distance' :object, 'Date_received': object,\n","              'Date': object}\n","test_offline_data_type = {'User_id': np.int64, 'Merchant_id': np.int64, 'Coupon_id': object,\n","              'Discount_rate': object, 'Distance' :object, 'Date_received': object}\n","train_online_data_type = {'User_id': np.int64, 'Merchant_id': np.int64, 'Action': np.int64,\n","              'Coupon_id': object, 'Discount_rate': object, 'Distance' :object,\n","              'Date_received': object}\n","              \n","test_offline = pd.read_csv('/content/drive/My Drive/Case/O2O Coupon Use Prediction/data/ccf_offline_stage1_test_revised.csv', dtype=test_offline_data_type)\n","train_offline = pd.read_csv('/content/drive/My Drive/Case/O2O Coupon Use Prediction/data/ccf_offline_stage1_train.csv', dtype=train_offline_data_type)\n","train_online = pd.read_csv('/content/drive/My Drive/Case/O2O Coupon Use Prediction/data/ccf_online_stage1_train.csv', dtype=train_online_data_type)\n","submission = pd.read_csv('/content/drive/My Drive/Case/O2O Coupon Use Prediction/data/sample_submission.csv')"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"id":"TZro_aEqO40a","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1595943436527,"user_tz":-480,"elapsed":9940,"user":{"displayName":"Jiatao LI","photoUrl":"","userId":"09800313012843676250"}},"outputId":"873e0c92-b1ba-4cbd-bd19-2b3d2f7c57b5"},"source":["print('test_offline dataset has {} rows and {} columns.'.format(test_offline.shape[0],test_offline.shape[1]))\n","print('train_offline dataset has {} rows and {} columns.'.format(train_offline.shape[0],train_offline.shape[1]))\n","print('train_online dataset has {} rows and {} columns.'.format(train_online.shape[0],train_online.shape[1]))\n","print('submission dataset has {} rows and {} columns.'.format(submission.shape[0],submission.shape[1]))"],"execution_count":85,"outputs":[{"output_type":"stream","text":["test_offline dataset has 113640 rows and 6 columns.\n","train_offline dataset has 1754884 rows and 7 columns.\n","train_online dataset has 11429826 rows and 7 columns.\n","submission dataset has 13 rows and 4 columns.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"MMRDu6HtO--a","colab_type":"text"},"source":["# 数据批注"]},{"cell_type":"code","metadata":{"id":"76XULNg5O5r2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595943506656,"user_tz":-480,"elapsed":79543,"user":{"displayName":"Jiatao LI","photoUrl":"","userId":"09800313012843676250"}}},"source":["def label(row):\n","    if row['Date_received'] is np.nan:\n","        return -1\n","    if row['Date'] is not np.nan:\n","        td = pd.to_datetime(row['Date'], format='%Y%m%d') -  pd.to_datetime(row['Date_received'], format='%Y%m%d')\n","        if td <= pd.Timedelta(15, 'D'):\n","            return 1\n","    return 0\n","train_offline['label'] = train_offline.apply(label, axis = 1)"],"execution_count":86,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MO8zv9sSPYOA","colab_type":"text"},"source":["## 转换时间"]},{"cell_type":"code","metadata":{"id":"KoqU2E5sQCmU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595943507108,"user_tz":-480,"elapsed":79431,"user":{"displayName":"Jiatao LI","photoUrl":"","userId":"09800313012843676250"}}},"source":["train_offline['Date'] = pd.to_datetime(train_offline['Date'], format='%Y%m%d')\n","train_offline['Date_received'] = pd.to_datetime(train_offline['Date_received'], format='%Y%m%d')\n","test_offline['Date_received'] = pd.to_datetime(test_offline['Date_received'], format='%Y%m%d')"],"execution_count":87,"outputs":[]},{"cell_type":"code","metadata":{"id":"E6yNL3f0cpYG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595943507109,"user_tz":-480,"elapsed":79188,"user":{"displayName":"Jiatao LI","photoUrl":"","userId":"09800313012843676250"}}},"source":["def convertRate(row):\n","    \"\"\"Convert discount to rate\"\"\"\n","    if row is np.nan:\n","        return 1.0\n","    elif ':' in row:\n","        rows = row.split(':')\n","        return 1.0 - float(rows[1])/float(rows[0])\n","    else:\n","        return float(row)"],"execution_count":88,"outputs":[]},{"cell_type":"code","metadata":{"id":"6BYBRfpmcvZf","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595943508066,"user_tz":-480,"elapsed":79829,"user":{"displayName":"Jiatao LI","photoUrl":"","userId":"09800313012843676250"}}},"source":["train_offline['discount'] = train_offline['Discount_rate'].apply(convertRate)\n","test_offline['discount'] = test_offline['Discount_rate'].apply(convertRate)\n","\n","train_offline['Distance'] = train_offline['Distance'].fillna(-1)\n","train_offline['Distance'] = train_offline['Distance'].astype(int)\n","train_offline.loc[train_offline['Distance']==-1,'Distance'] = np.nan\n","test_offline['Distance'] = test_offline['Distance'].fillna(-1)\n","test_offline['Distance'] = test_offline['Distance'].astype(int)\n","test_offline.loc[test_offline['Distance']==-1,'Distance'] = np.nan"],"execution_count":89,"outputs":[]},{"cell_type":"code","metadata":{"id":"OlBPY8hhRBiN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595946514903,"user_tz":-480,"elapsed":1153,"user":{"displayName":"Jiatao LI","photoUrl":"","userId":"09800313012843676250"}}},"source":["train = train_offline.copy()\n","test = test_offline.copy()"],"execution_count":96,"outputs":[]},{"cell_type":"code","metadata":{"id":"CossZ6n2x845","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595943511275,"user_tz":-480,"elapsed":82190,"user":{"displayName":"Jiatao LI","photoUrl":"","userId":"09800313012843676250"}}},"source":["def get_offline_features(X, offline):\n","    # X = X[:1000]\n","\n","    print(len(X), len(X.columns))\n","\n","    coupon_id_notnull = offline[offline.Coupon_id.notnull()]\n","\n","    temp = coupon_id_notnull\n","    coupon_consume = temp[temp.Date.notnull()]\n","    coupon_no_consume = temp[temp.Date.isnull()]\n","\n","    user_coupon_consume = coupon_consume.groupby('User_id')\n","\n","    X['weekday'] = X.Date_received.dt.weekday\n","    X['day'] = X.Date_received.dt.day\n","\n","    # # 距离优惠券消费次数\n","    # temp = coupon_consume.groupby('Distance').size().reset_index(name='distance_0')\n","    # X = pd.merge(X, temp, how='left', on='Distance')\n","    #\n","    # # 距离优惠券不消费次数\n","    # temp = coupon_no_consume.groupby('Distance').size().reset_index(name='distance_1')\n","    # X = pd.merge(X, temp, how='left', on='Distance')\n","    #\n","    # # 距离优惠券领取次数\n","    # X['distance_2'] = X.distance_0 + X.distance_1\n","    #\n","    # # 距离优惠券消费率\n","    # X['distance_3'] = X.distance_0 / X.distance_2\n","\n","    # temp = coupon_consume[coupon_consume.Distance != 11].groupby('Distance').size()\n","    # temp['d4'] = temp.Distance.sum() / len(temp)\n","    # X = pd.merge(X, temp, how='left', on='Distance')\n","\n","    '''user features'''\n","\n","    # 用户优惠券消费次数\n","    temp = user_coupon_consume.size().reset_index(name='u2')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户优惠券不消费次数\n","    temp = coupon_no_consume.groupby('User_id').size().reset_index(name='u3')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户优惠券消费与不消费次数比值\n","    X['u19'] = X.u2 / X.u3\n","\n","    # 用户领取优惠券次数\n","    X['u1'] = X.u2.fillna(0) + X.u3.fillna(0)\n","\n","    # 用户优惠券使用率\n","    X['u4'] = X.u2 / X.u1\n","\n","    # 用户普通消费次数\n","    date_received_isnull_date_notnull = offline[offline.Date_received.isnull() & offline.Date.notnull()]\n","\n","    temp = date_received_isnull_date_notnull.groupby('User_id').size().reset_index(name='u5')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户优惠券消费和普通消费次数\n","    X['u25'] = X.u2 + X.u5\n","\n","    # 用户使用优惠券消费占比\n","    X['u20'] = X.u2 / X.u25\n","\n","    # 用户所有消费平均间隔\n","    temp = offline[offline.Date.notnull()]\n","    temp = pd.merge(temp, temp.groupby('User_id').Date.max().reset_index(name='_max'))\n","    temp = pd.merge(temp, temp.groupby('User_id').Date.min().reset_index(name='_min'))\n","    temp = pd.merge(temp, temp.groupby('User_id').size().reset_index(name='_len'))\n","    temp['u6'] = (temp._max - temp._min).dt.days / (temp._len - 1)\n","    temp.drop_duplicates('User_id', inplace=True)\n","    X = pd.merge(X, temp[['User_id', 'u6']], how='left', on='User_id')\n","\n","    # 用户普通消费平均间隔\n","    temp = date_received_isnull_date_notnull\n","    temp = pd.merge(temp, temp.groupby('User_id').Date.max().reset_index(name='_max'))\n","    temp = pd.merge(temp, temp.groupby('User_id').Date.min().reset_index(name='_min'))\n","    temp = pd.merge(temp, temp.groupby('User_id').size().reset_index(name='_len'))\n","    temp['u26'] = (temp._max - temp._min).dt.days / (temp._len - 1)\n","    temp.drop_duplicates('User_id', inplace=True)\n","    X = pd.merge(X, temp[['User_id', 'u26']], how='left', on='User_id')\n","\n","    # 用户优惠券消费平均间隔\n","    temp = pd.merge(coupon_consume, user_coupon_consume.Date.max().reset_index(name='_max'))\n","    temp = pd.merge(temp, temp.groupby('User_id').Date.min().reset_index(name='_min'))\n","    temp = pd.merge(temp, temp.groupby('User_id').size().reset_index(name='_len'))\n","    temp['u7'] = (temp._max - temp._min).dt.days / (temp._len - 1)\n","    temp.drop_duplicates('User_id', inplace=True)\n","    X = pd.merge(X, temp[['User_id', 'u7']], how='left', on='User_id')\n","\n","    # 用户15天内平均会普通消费几次\n","    X['u8'] = X.u6 / 15\n","\n","    # 用户15天内平均会优惠券消费几次\n","    X['u9'] = X.u7 / 15\n","\n","    # 用户优惠券领取到使用平均间隔\n","    temp = coupon_consume.copy()\n","    temp['days'] = (temp.Date - temp.Date_received).dt.days\n","    temp = (temp.groupby('User_id').days.sum() / temp.groupby('User_id').size()).reset_index(name='u10')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户在15天内使用掉优惠券的值大小\n","    X['u11'] = X.u10 / 15\n","\n","    # 领取优惠券到使用优惠券间隔小于15天的次数\n","    temp = coupon_consume.copy()\n","    temp['days'] = (temp.Date - temp.Date_received).dt.days\n","    temp = temp[temp.days <= 15]\n","    temp = temp.groupby('User_id').size().reset_index(name='u21')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户15天使用掉优惠券的次数除以使用优惠券的次数\n","    X['u22'] = X.u21 / X.u2\n","\n","    # 用户15天使用掉优惠券的次数除以领取优惠券未消费的次数\n","    X['u23'] = X.u21 / X.u3\n","\n","    # 用户15天使用掉优惠券的次数除以领取优惠券的总次数\n","    X['u24'] = X.u21 / X.u1\n","\n","    # 用户核销优惠券的平均折率\n","    temp = user_coupon_consume.discount.mean().reset_index(name='u45')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户核销优惠券的最低折率\n","    temp = user_coupon_consume.discount.min().reset_index(name='u27')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户核销优惠券的最高消费折率\n","    temp = user_coupon_consume.discount.max().reset_index(name='u28')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户核销过的不同优惠券数量\n","    temp = coupon_consume.groupby(['User_id', 'Coupon_id']).size()\n","    temp = temp.groupby('User_id').size().reset_index(name='u32')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户领取所有不同优惠券数量\n","    date_received_notnull = offline[offline.Date_received.notnull()]\n","    temp = date_received_notnull\n","    temp = temp.groupby(['User_id', 'Coupon_id']).size().reset_index(name='u47')\n","    X = pd.merge(X, temp, how='left', on=['User_id', 'Coupon_id'])\n","\n","    # 用户核销过的不同优惠券数量占所有不同优惠券的比重\n","    X['u33'] = X.u32 / X.u47\n","\n","    # 用户平均每种优惠券核销多少张\n","    X['u34'] = X.u2 / X.u47\n","\n","    # 核销优惠券用户-商家平均距离\n","    temp = offline[offline.Coupon_id.notnull() & offline.Date.notnull() & offline.Distance.notnull()]\n","    temp = temp.groupby('User_id').Distance\n","    temp = pd.merge(temp.count().reset_index(name='x'), temp.sum().reset_index(name='y'), on='User_id')\n","    temp['u35'] = temp.y / temp.x\n","    temp = temp[['User_id', 'u35']]\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户核销优惠券中的最小用户-商家距离\n","    temp = coupon_consume[coupon_consume.Distance.notnull()]\n","    temp = temp.groupby('User_id').Distance.min().reset_index(name='u36')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户核销优惠券中的最大用户-商家距离\n","    temp = coupon_consume[coupon_consume.Distance.notnull()]\n","    temp = temp.groupby('User_id').Distance.max().reset_index(name='u37')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 优惠券类型\n","    discount_types = [\n","        '0.2', '0.5', '0.6', '0.7', '0.75', '0.8', '0.85', '0.9', '0.95', '30:20', '50:30', '10:5',\n","        '20:10', '100:50', '200:100', '50:20', '30:10', '150:50', '100:30', '20:5', '200:50', '5:1',\n","        '50:10', '100:20', '150:30', '30:5', '300:50', '200:30', '150:20', '10:1', '50:5', '100:10',\n","        '200:20', '300:30', '150:10', '300:20', '500:30', '20:1', '100:5', '200:10', '30:1', '150:5',\n","        '300:10', '200:5', '50:1', '100:1',\n","    ]\n","    X['discount_type'] = -1\n","    for k, v in enumerate(discount_types):\n","        X.loc[X.Discount_rate == v, 'discount_type'] = k\n","\n","    # 不同优惠券领取次数\n","    temp = offline.groupby(['User_id', 'Discount_rate']).size().reset_index(name='u41')\n","    X = pd.merge(X, temp, how='left', on=['User_id', 'Discount_rate'])\n","\n","    # 不同优惠券使用次数\n","    temp = coupon_consume.groupby(['User_id', 'Discount_rate']).size().reset_index(name='u42')\n","    X = pd.merge(X, temp, how='left', on=['User_id', 'Discount_rate'])\n","\n","    # 不同优惠券不使用次数\n","    temp = coupon_no_consume.groupby(['User_id', 'Discount_rate']).size().reset_index(name='u43')\n","    X = pd.merge(X, temp, how='left', on=['User_id', 'Discount_rate'])\n","\n","    # 不同打折优惠券使用率\n","    X['u44'] = X.u42 / X.u41\n","\n","    # 满减类型优惠券领取次数\n","    temp = offline[offline.Discount_rate.str.contains(':') == True]\n","    temp = temp.groupby('User_id').size().reset_index(name='u48')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 打折类型优惠券领取次数\n","    temp = offline[offline.Discount_rate.str.contains('\\.') == True]\n","    temp = temp.groupby('User_id').size().reset_index(name='u49')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    '''offline merchant features'''\n","\n","    # 商家销售次数\n","    temp = offline[offline.Date.notnull()].groupby('Merchant_id').size().reset_index(name='m0')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商家优惠券核销次数\n","    temp = coupon_consume.groupby('Merchant_id').size().reset_index(name='m1')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商家普通销售次数\n","    X['m2'] = X.m0.fillna(0) - X.m1.fillna(0)\n","\n","    # 商家优惠券被领取次数\n","    temp = date_received_notnull.groupby('Merchant_id').size().reset_index(name='m3')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商家优惠券核销率\n","    X['m4'] = X.m1 / X.m3\n","\n","    # 商家优惠券不核销次数\n","    temp = coupon_no_consume.groupby('Merchant_id').size().reset_index(name='m7')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商家在数据集中出现的次数\n","    temp = offline.groupby('Merchant_id').size().reset_index(name='m16')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商户当天优惠券领取次数\n","    temp = X[X.Date_received.notnull()]\n","    temp = temp.groupby(['Merchant_id', 'Date_received']).size().reset_index(name='m5')\n","    X = pd.merge(X, temp, how='left', on=['Merchant_id', 'Date_received'])\n","\n","    # 商家当天优惠券领取人数\n","    temp = X[X.Date_received.notnull()]\n","    temp = temp.groupby(['User_id', 'Merchant_id', 'Date_received']).size()\n","    temp = temp.groupby(['Merchant_id', 'Date_received']).size().reset_index(name='m6')\n","    X = pd.merge(X, temp, how='left', on=['Merchant_id', 'Date_received'])\n","\n","    # 商家核销优惠券的平均折率\n","    temp = coupon_consume.groupby('Merchant_id').discount.mean().reset_index(name='m8')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商家优惠券核销的最小消费折率\n","    temp = coupon_consume.groupby('Merchant_id').discount.max().reset_index(name='m9')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商家优惠券核销的最大消费折率\n","    temp = coupon_consume.groupby('Merchant_id').discount.min().reset_index(name='m10')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商家优惠券核销不同的用户数量\n","    temp = coupon_consume.groupby(['Merchant_id', 'User_id']).size()\n","    temp = temp.groupby('Merchant_id').size().reset_index(name='m11')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商家优惠券领取不同的用户数量\n","    temp = date_received_notnull.groupby(['Merchant_id', 'User_id']).size()\n","    temp = temp.groupby('Merchant_id').size().reset_index(name='m12')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 核销商家优惠券的不同用户数量其占领取不同的用户比重\n","    X['m13'] = X.m11 / X.m12\n","\n","    # 商家优惠券平均每个用户核销多少张\n","    X['m14'] = X.m1 / X.m12\n","\n","    # 商家被核销过的不同优惠券数量\n","    temp = coupon_consume.groupby(['Merchant_id', 'Coupon_id']).size()\n","    temp = temp.groupby('Merchant_id').size().reset_index(name='m15')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商家领取过的不同优惠券数量的比重\n","    temp = date_received_notnull.groupby(['Merchant_id', 'Coupon_id']).size()\n","    temp = temp.groupby('Merchant_id').count().reset_index(name='m18')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商家被核销过的不同优惠券数量占所有领取过的不同优惠券数量的比重\n","    X['m19'] = X.m15 / X.m18\n","\n","    # 商家被核销优惠券的平均时间\n","    temp = pd.merge(coupon_consume, coupon_consume.groupby('Merchant_id').Date.max().reset_index(name='_max'))\n","    temp = pd.merge(temp, temp.groupby('Merchant_id').Date.min().reset_index(name='_min'))\n","    temp = pd.merge(temp, temp.groupby('Merchant_id').size().reset_index(name='_len'))\n","    temp['m20'] = (temp._max - temp._min).dt.days / (temp._len - 1)\n","    temp.drop_duplicates('Merchant_id', inplace=True)\n","    X = pd.merge(X, temp[['Merchant_id', 'm20']], how='left', on='Merchant_id')\n","\n","    # 商家被核销优惠券中的用户平均距离\n","    temp = coupon_consume[coupon_consume.Distance.notnull()].groupby('Merchant_id').Distance\n","    temp = pd.merge(temp.count().reset_index(name='x'), temp.sum().reset_index(name='y'), on='Merchant_id')\n","    temp['m21'] = temp.y / temp.x\n","    temp = temp[['Merchant_id', 'm21']]\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商家被核销优惠券中的用户最小距离\n","    temp = coupon_consume[coupon_consume.Distance.notnull()]\n","    temp = temp.groupby('Merchant_id').Distance.min().reset_index(name='m22')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商家被核销优惠券中的用户最大距离\n","    temp = coupon_consume[coupon_consume.Distance.notnull()]\n","    temp = temp.groupby('Merchant_id').Distance.max().reset_index(name='m23')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商家普通消费用户的平均距离\n","    # temp = offline[pd.isnull(offline.Date_received) & pd.notnull(offline.Date) & pd.notnull(offline.Distance)]\n","    # temp = temp.groupby('Merchant_id').Distance\n","    # temp = pd.merge(temp.count().reset_index(name='x'), temp.sum().reset_index(name='y'), on='Merchant_id')\n","    # temp['m24'] = temp.y / temp.x\n","    # temp = temp[['Merchant_id', 'm24']]\n","    # X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    \"\"\"offline coupon features\"\"\"\n","\n","    # 每种优惠券领取次数\n","    temp = coupon_id_notnull.groupby('Coupon_id').size().reset_index(name='c1')\n","    X = pd.merge(X, temp, how='left', on='Coupon_id')\n","\n","    # 每种优惠券使用次数\n","    temp = coupon_consume.groupby('Coupon_id').size().reset_index(name='c2')\n","    X = pd.merge(X, temp, how='left', on='Coupon_id')\n","\n","    # 优惠券使用率\n","    X['c3'] = X.c2 / X.c1\n","\n","    # 优惠券没有使用次数\n","    X['c4'] = X.c1 - X.c2\n","\n","    # 优惠券当天领取次数\n","    temp = X.groupby(['Coupon_id', 'Date_received']).size().reset_index(name='c5')\n","    X = pd.merge(X, temp, how='left', on=['Coupon_id', 'Date_received'])\n","\n","    # 优惠券类型(直接优惠为0, 满减为1)\n","    X['c6'] = 0\n","    X.loc[X.Discount_rate.str.contains(':') == True, 'c6'] = 1\n","\n","    # 不同打折优惠券领取次数\n","    temp = offline.groupby('Discount_rate').size().reset_index(name='c8')\n","    X = pd.merge(X, temp, how='left', on='Discount_rate')\n","\n","    # 不同打折优惠券使用次数\n","    temp = coupon_consume.groupby('Discount_rate').size().reset_index(name='c9')\n","    X = pd.merge(X, temp, how='left', on='Discount_rate')\n","\n","    # 不同打折优惠券不使用次数\n","    temp = coupon_no_consume.groupby('Discount_rate').size().reset_index(name='c10')\n","    X = pd.merge(X, temp, how='left', on='Discount_rate')\n","\n","    # 不同打折优惠券使用率\n","    X['c11'] = X.c9 / X.c8\n","\n","    # 每种优惠券核销的平均时间\n","    temp = pd.merge(coupon_consume, coupon_consume.groupby('Coupon_id').Date.max().reset_index(name='_max'))\n","    temp = pd.merge(temp, temp.groupby('Coupon_id').Date.min().reset_index(name='_min'))\n","    temp = pd.merge(temp, temp.groupby('Coupon_id').size().reset_index(name='_len'))\n","    temp['c12'] = (temp._max - temp._min).dt.days / (temp._len - 1)\n","    temp.drop_duplicates('Coupon_id', inplace=True)\n","    X = pd.merge(X, temp[['Coupon_id', 'c12']], how='left', on='Coupon_id')\n","\n","    '''user merchant feature'''\n","\n","    # 用户领取商家的优惠券次数\n","    temp = coupon_id_notnull\n","    temp = temp.groupby(['User_id', 'Merchant_id']).size().reset_index(name='um1')\n","    X = pd.merge(X, temp, how='left', on=['User_id', 'Merchant_id'])\n","\n","    # 用户领取商家的优惠券后不核销次数\n","    temp = coupon_no_consume.groupby(['User_id', 'Merchant_id']).size().reset_index(name='um2')\n","    X = pd.merge(X, temp, how='left', on=['User_id', 'Merchant_id'])\n","\n","    # 用户领取商家的优惠券后核销次数\n","    temp = coupon_consume.groupby(['User_id', 'Merchant_id']).size().reset_index(name='um3')\n","    X = pd.merge(X, temp, how='left', on=['User_id', 'Merchant_id'])\n","\n","    # 用户领取商家的优惠券后核销率\n","    X['um4'] = X.um3 / X.um1\n","\n","    # 用户对每个商家的不核销次数占用户总的不核销次数的比重\n","    temp = coupon_no_consume.groupby('User_id').size().reset_index(name='temp')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","    X['um5'] = X.um2 / X.temp\n","    X.drop(columns='temp', inplace=True)\n","\n","    # 用户在商店总共消费过几次\n","    temp = offline[offline.Date.notnull()].groupby(['User_id', 'Merchant_id']).size().reset_index(name='um6')\n","    X = pd.merge(X, temp, how='left', on=['User_id', 'Merchant_id'])\n","\n","    # 用户在商店普通消费次数\n","    temp = date_received_isnull_date_notnull\n","    temp = temp.groupby(['User_id', 'Merchant_id']).size().reset_index(name='um7')\n","    X = pd.merge(X, temp, how='left', on=['User_id', 'Merchant_id'])\n","\n","    # 用户当天在每个商家领取的优惠券次数\n","    temp = date_received_notnull\n","    temp = temp.groupby(['User_id', 'Merchant_id', 'Date_received']).size().reset_index(name='um8')\n","    X = pd.merge(X, temp, how='left', on=['User_id', 'Merchant_id', 'Date_received'])\n","\n","    # 用户领取优惠券不同商家数量\n","    temp = coupon_id_notnull\n","    temp = temp.groupby(['User_id', 'Merchant_id']).size().reset_index()\n","    temp = temp.groupby('User_id').size().reset_index(name='um9')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户核销优惠券不同商家数量\n","    temp = coupon_consume.groupby(['User_id', 'Merchant_id']).size()\n","    temp = temp.groupby('User_id').size().reset_index(name='um10')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户核销过优惠券的不同商家数量占所有不同商家的比重\n","    X['um11'] = X.um10 / X.um9\n","\n","    # 用户平均核销每个商家多少张优惠券\n","    X['um12'] = X.u2 / X.um9\n","\n","    '''other feature'''\n","\n","    # 用户领取优惠券次数\n","    temp = X.groupby('User_id').size().reset_index(name='o1')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户不同优惠券领取次数\n","    temp = X.groupby(['User_id', 'Coupon_id']).size().reset_index(name='o2')\n","    X = pd.merge(X, temp, how='left', on=['User_id', 'Coupon_id'])\n","\n","    # 用户此次之后/前领取的优惠券次数\n","    X['o3'] = 1\n","    X['o3'] = X.sort_values(by=['User_id', 'Date_received']).groupby('User_id').o3.cumsum() - 1\n","    X['o4'] = 1\n","    X['o4'] = X.sort_values(by=['User_id', 'Date_received'], ascending=False).groupby('User_id').o4.cumsum() - 1\n","\n","    # 用户此次之后/前领取的每种优惠券次数\n","    X['o5'] = 1\n","    temp = X.sort_values(by=['User_id', 'Coupon_id', 'Date_received'])\n","    X['o5'] = temp.groupby('User_id').o5.cumsum() - 1\n","    X['o6'] = 1\n","    temp = X.sort_values(by=['User_id', 'Coupon_id', 'Date_received'], ascending=False)\n","    X['o6'] = temp.groupby('User_id').o6.cumsum() - 1\n","\n","    # 用户领取优惠券平均时间间隔\n","    temp = pd.merge(X, X.groupby('User_id').Date_received.max().reset_index(name='_max'))\n","    temp = pd.merge(temp, temp.groupby('User_id').Date_received.min().reset_index(name='_min'))\n","    temp = pd.merge(temp, temp.groupby('User_id').size().reset_index(name='_len'))\n","    temp['o7'] = (temp._max - temp._min).dt.days / (temp._len - 1)\n","    temp.drop_duplicates('User_id', inplace=True)\n","    X = pd.merge(X, temp[['User_id', 'o7']], how='left', on='User_id')\n","\n","    # 用户领取不同商家的优惠券次数\n","    temp = X.groupby(['User_id', 'Merchant_id']).size().reset_index(name='o8')\n","    X = pd.merge(X, temp, how='left', on=['User_id', 'Merchant_id'])\n","\n","    # 用户领取的不同商家数\n","    temp = X.groupby(['User_id', 'Merchant_id']).size()\n","    temp = temp.groupby('User_id').size().reset_index(name='o9')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户当天领取的优惠券次数\n","    temp = X.groupby(['User_id', 'Date_received']).size().reset_index(name='o10')\n","    X = pd.merge(X, temp, how='left', on=['User_id', 'Date_received'])\n","\n","    # 用户当天不同优惠券领取次数\n","    temp = X.groupby(['User_id', 'Coupon_id', 'Date_received']).size().reset_index(name='o11')\n","    X = pd.merge(X, temp, how='left', on=['User_id', 'Coupon_id', 'Date_received'])\n","\n","    # 用户领取优惠券类别数\n","    temp = X.groupby(['User_id', 'Coupon_id']).size()\n","    temp = temp.groupby('User_id').size().reset_index(name='o12')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 商家被领取的优惠券次数\n","    temp = X.groupby('Merchant_id').size().reset_index(name='o13')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商家优惠券的种类数\n","    temp = X.groupby(['Merchant_id', 'Coupon_id']).size().reset_index(name='o14')\n","    X = pd.merge(X, temp, how='left', on=['Merchant_id', 'Coupon_id'])\n","\n","    # 商家被领取优惠券不同用户数\n","    temp = X.groupby(['Merchant_id', 'User_id']).size()\n","    temp = temp.groupby('Merchant_id').size().reset_index(name='o15')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 商家优惠券所有种类数\n","    temp = X.groupby(['Merchant_id', 'Coupon_id']).size()\n","    temp = temp.groupby('Merchant_id').size().reset_index(name='o16')\n","    X = pd.merge(X, temp, how='left', on='Merchant_id')\n","\n","    # 用户领取优惠券的时间间隔\n","    temp = X.sort_values(by=['User_id', 'Date_received']).groupby('User_id')\n","    X['o17'] = temp.Date_received.diff().dt.days\n","    X['o18'] = temp.Date_received.diff(-1).dt.days.abs()\n","\n","    print(len(X), len(X.columns))\n","\n","    return X\n","\n","\n","def get_online_features(X, online):\n","    # temp = online[online.Coupon_id == online.Coupon_id]\n","    # coupon_consume = temp[temp.Date == temp.Date]\n","    # coupon_no_consume = temp[temp.Date != temp.Date]\n","\n","    # 用户操作次数\n","    temp = online.groupby('User_id').size().reset_index(name='on_u1')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户点击次数\n","    temp = online[online.Action == 0].groupby('User_id').size().reset_index(name='on_u2')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户点击率\n","    X['on_u3'] = X.on_u2 / X.on_u1\n","\n","    # 用户购买次数\n","    temp = online[online.Action == 1].groupby('User_id').size().reset_index(name='on_u4')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户线上购买率\n","    X['on_u5'] = X.on_u4 / X.on_u1\n","\n","    # 用户领取优惠券次数\n","    temp = online[online.Date_received.notnull()].groupby('User_id').size().reset_index(name='on_u6')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户优惠券领取率\n","    X['on_u7'] = X.on_u6 / X.on_u1\n","\n","    # 用户优惠券消费次数\n","    temp = online[online.Date_received.notnull() & online.Date.notnull()]\n","    temp = temp.groupby('User_id').size().reset_index(name='on_u9')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户优惠券不消费次数\n","    temp = online[online.Date_received.notnull() & online.Date.isnull()]\n","    temp = temp.groupby('User_id').size().reset_index(name='on_u8')\n","    X = pd.merge(X, temp, how='left', on='User_id')\n","\n","    # 用户优惠券核销率\n","    X['on_u10'] = X.on_u9 / X.on_u6\n","\n","    # 用户线下不消费次数占线上线下总的不消费次数的比重\n","    X['on_u11'] = X.u3 / (X.on_u8.fillna(0) + X.u3.fillna(0))\n","\n","    # 用户线下的优惠券核销次数占线上线下总的优惠券核销次数的比重\n","    X['on_u12'] = X.u2 / (X.on_u9.fillna(0) + X.u2.fillna(0))\n","\n","    # 用户线下领取的记录数量占总的记录数量的比重\n","    X['on_u13'] = X.u1 / (X.on_u6.fillna(0) + X.u1.fillna(0))\n","\n","    # # 消费优惠券的平均折率\n","    # temp = coupon_consume.groupby('User_id').discount.mean().reset_index(name='ou14')\n","    # X = pd.merge(X, temp, how='left', on='User_id')\n","    #\n","    # # 用户核销优惠券的最低消费折率\n","    # temp = coupon_consume.groupby('User_id').discount.min().reset_index(name='ou15')\n","    # X = pd.merge(X, temp, how='left', on='User_id')\n","    #\n","    # # 用户核销优惠券的最高消费折率\n","    # temp = coupon_consume.groupby('User_id').discount.max().reset_index(name='ou16')\n","    # X = pd.merge(X, temp, how='left', on='User_id')\n","    #\n","    # # 不同打折优惠券领取次数\n","    # temp = online.groupby('Discount_rate').size().reset_index(name='oc1')\n","    # X = pd.merge(X, temp, how='left', on='Discount_rate')\n","    #\n","    # # 不同打折优惠券使用次数\n","    # temp = coupon_consume.groupby('Discount_rate').size().reset_index(name='oc2')\n","    # X = pd.merge(X, temp, how='left', on='Discount_rate')\n","    #\n","    # # 不同打折优惠券不使用次数\n","    # temp = coupon_no_consume.groupby('Discount_rate').size().reset_index(name='oc3')\n","    # X = pd.merge(X, temp, how='left', on='Discount_rate')\n","    #\n","    # # 不同打折优惠券使用率\n","    # X['oc4'] = X.oc2 / X.oc1\n","\n","    print(len(X), len(X.columns))\n","    print('----------')\n","\n","    return X\n"],"execution_count":91,"outputs":[]},{"cell_type":"code","metadata":{"id":"zBSK3DEaSmGb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"executionInfo":{"status":"ok","timestamp":1595946586559,"user_tz":-480,"elapsed":63807,"user":{"displayName":"Jiatao LI","photoUrl":"","userId":"09800313012843676250"}},"outputId":"53748352-22dd-4872-d561-c5221b216c9d"},"source":["train = get_offline_features(train, train_offline)\n","train = get_online_features(train, train_online)\n","test = get_offline_features(test, train_offline)\n","test = get_online_features(test, train_online)"],"execution_count":97,"outputs":[{"output_type":"stream","text":["113640 6\n","113640 108\n","113640 121\n","----------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uKK9Krf71PJc","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1595946782216,"user_tz":-480,"elapsed":1244,"user":{"displayName":"Jiatao LI","photoUrl":"","userId":"09800313012843676250"}},"outputId":"623c7ddb-ebda-48aa-a8f8-0eadc8edd2e5"},"source":["print('test_ dataset has {} rows and {} columns.'.format(test.shape[0],test.shape[1]))\n","print('train_ dataset has {} rows and {} columns.'.format(train.shape[0],train.shape[1]))"],"execution_count":105,"outputs":[{"output_type":"stream","text":["test_ dataset has 113640 rows and 122 columns.\n","train_ dataset has 1754884 rows and 124 columns.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hdknXYae1fc6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1595946798596,"user_tz":-480,"elapsed":870,"user":{"displayName":"Jiatao LI","photoUrl":"","userId":"09800313012843676250"}},"outputId":"d6c79bf6-d8da-46b6-aa9e-500a41c80e39"},"source":["test_features = test.columns\n","trainfeatures = train.columns\n","\n","for feature in trainfeatures:\n","  if feature not in test_features:\n","    print(feature)"],"execution_count":107,"outputs":[{"output_type":"stream","text":["Date\n","label\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nIPCw75Zqpgs","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1595947016169,"user_tz":-480,"elapsed":209683,"user":{"displayName":"Jiatao LI","photoUrl":"","userId":"09800313012843676250"}}},"source":["train.to_csv('/content/drive/My Drive/Case/O2O Coupon Use Prediction/data/train2.csv', index=0)\n","test.to_csv('/content/drive/My Drive/Case/O2O Coupon Use Prediction/data/test2.csv', index=0)"],"execution_count":108,"outputs":[]},{"cell_type":"code","metadata":{"id":"g0rOqHBOqzBQ","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}